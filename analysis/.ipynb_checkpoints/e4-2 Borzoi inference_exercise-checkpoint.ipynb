{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b23d8b0",
   "metadata": {},
   "source": [
    "# e4-2 Borzoi Inference Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92068463",
   "metadata": {},
   "source": [
    "The exercise uses a python package `grelu` to make predictions for a given DNA sequence. It uses a pre-trained Borzoi model to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea895af",
   "metadata": {},
   "source": [
    "About the grelu package:  \n",
    "    - github repo: https://github.com/Genentech/gReLU  \n",
    "    - citation Lal, A. et al. Decoding sequence determinants of gene expression in diverse cellular and disease states. bioRxiv 2024.10.09.617507 (2024) doi:10.1101/2024.10.09.617507."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058227b",
   "metadata": {},
   "source": [
    "About Borzoi: Linder, J., Srivastava, D., Yuan, H., Agarwal, V. & Kelley, D. R. Predicting RNA-seq coverage from DNA sequence as a unifying model of gene regulation. Nat. Genet. 57, 949–961 (2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ded9e",
   "metadata": {},
   "source": [
    "## Before the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60125ce",
   "metadata": {},
   "source": [
    "On discovery set up a conda environment and install grelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6704259",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3306148305.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3370472/3306148305.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda create --name py10 python=3.10\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "source /optnfs/common/miniconda3/etc/profile.d/conda.sh\n",
    "conda create --name py10 python=3.10\n",
    "conda activate py10\n",
    "pip install grelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d819c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run python \n",
    "python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fafeed",
   "metadata": {},
   "source": [
    "You should be an in interactive python session now. We'll execute the rest of the code in this python shell in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e62ee",
   "metadata": {},
   "source": [
    "* An alternative way to install grelu: If you have >50gb disk space, you can try the following way to set up grelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2aa2cf",
   "metadata": {},
   "source": [
    "Navigate to your lab share and create container directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891e6920",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3531433326.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3370472/3531433326.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mkdir containers\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# cd to your lab share. You home directory only has 45G, so it is not suitable to install by this way.\n",
    "mkdir containers\n",
    "cd containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a810c2",
   "metadata": {},
   "source": [
    "Pull image to container directory, this step will take ~ 10 min. It would require at least 10GB storage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa6954",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "singularity pull --dir ~/containers docker://nvcr.io/nvidia/pytorch:24.08-py3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c694532",
   "metadata": {},
   "source": [
    "Build a sandbox from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93746c39",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "singularity build --sandbox inference_pytorch_24.08-py3/ pytorch_24.08-py3.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e897f93",
   "metadata": {},
   "source": [
    "Initialize Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd97543",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CONTAINER_NAME=\"inference_pytorch_24.08-py3/\"\n",
    "PROJECT_BASE=\"/dartfs-hpc/rc/home/j/$netID\" # Change as needed\n",
    "CONTAINER_LOCATION=\"/dartfs-hpc/rc/home/j/$netID/containers/$CONTAINER_NAME\" # I use /dartfs/rc/lab/S/Szhao/grahams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e78ce",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_BASE=\"/dartfs/rc/lab/S/Szhao/grahams\"\n",
    "CONTAINER_LOCATION=\"/dartfs/rc/lab/S/Szhao/grahams/containers/$CONTAINER_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ac7b5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export PATH=$PATH:/root/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b877d6b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "singularity shell --fakeroot --writable --nv --contain \\\n",
    "--home \"${PROJECT_BASE}:/root\" \\\n",
    "\"${CONTAINER_LOCATION}\" bash -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8b30d",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "pip install grelu\n",
    "export WANDB_MODE=disabled\n",
    "python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1fe86",
   "metadata": {},
   "source": [
    "You should be an in interactive python session now. We'll execute the rest of the code in this python shell in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540a954",
   "metadata": {},
   "source": [
    "# predict features based on input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614dfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2785b8",
   "metadata": {},
   "source": [
    "Load the pre-trained Borzoi model from the GreLU model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce53d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grelu.resources\n",
    "model = grelu.resources.load_model(\n",
    "    project=\"borzoi\",\n",
    "    model_name=\"human_rep0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467f365",
   "metadata": {},
   "source": [
    "Check model metadata and trained cell contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72982c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.DataFrame(model.data_params['tasks'])\n",
    "tasks.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cacd01",
   "metadata": {},
   "source": [
    "View Borzoi hyperparameters and training intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.data_params['train'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf331c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in model.data_params['train'].keys():\n",
    "    if key !=\"intervals\":\n",
    "        print(key, model.data_params['train'][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.data_params['train']['intervals']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf50b9",
   "metadata": {},
   "source": [
    "Make the inference intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447369f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = model.data_params[\"train\"][\"seq_len\"]\n",
    "chrom = \"chr1\"\n",
    "input_start = 69993520\n",
    "input_end = input_start + input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_intervals = pd.DataFrame({\n",
    "    'chrom':[chrom], 'start':[input_start], 'end':[input_end], \"strand\":[\"+\"],\n",
    "})\n",
    "\n",
    "input_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaf3331",
   "metadata": {},
   "source": [
    "Extract sequence using GENCODE assembly (takes a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grelu.sequence.format\n",
    "\n",
    "input_seqs = grelu.sequence.format.convert_input_type(\n",
    "    input_intervals,\n",
    "    output_type=\"strings\",\n",
    "    genome=\"hg38\"\n",
    ")\n",
    "input_seq = input_seqs[0]\n",
    "\n",
    "len(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59eda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723b01f",
   "metadata": {},
   "source": [
    "Run inference on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ead2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "preds = model.predict_on_seqs(input_seqs, device=device)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73784036",
   "metadata": {},
   "source": [
    "Note the shape of preds: it’s in the format Batch, Tasks, Length. So we have 1 sequence, 7611 tasks, and 6144 bins along the length axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6f8a9",
   "metadata": {},
   "source": [
    "Get output intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07357498",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_intervals = model.input_intervals_to_output_intervals(input_intervals)\n",
    "output_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_start = output_intervals.start[0]\n",
    "output_end = output_intervals.end[0]\n",
    "output_len = output_end - output_start\n",
    "print(output_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a1817",
   "metadata": {},
   "source": [
    "Save output predictions as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7316239",
   "metadata": {},
   "outputs": [],
   "source": [
    "cage_brain_tasks = tasks[(tasks.assay==\"CAGE\") & (tasks[\"sample\"].str.contains(\"brain\"))].head(2)\n",
    "rna_brain_tasks = tasks[(tasks.assay==\"RNA\") & (tasks[\"sample\"].str.contains(\"brain\"))].head(2)\n",
    "\n",
    "tasks_to_plot = cage_brain_tasks.index.tolist() + rna_brain_tasks.index.tolist()\n",
    "task_names = tasks.description[tasks_to_plot].tolist() # Description of these tracks from the `tasks` dataframe\n",
    "\n",
    "print(tasks_to_plot)\n",
    "print(task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = grelu.visualize.plot_tracks(\n",
    "    preds[0, tasks_to_plot, :],  # Outputs to plot\n",
    "    start_pos=output_start,      # Start coordinate for the x-axis label\n",
    "    end_pos=output_end,         # End coordinate for the x-axis label\n",
    "    titles=task_names,          # Titles for each track\n",
    "    figsize=(10, 3.5),           # Width, height\n",
    ")\n",
    "\n",
    "# Save the figure as a JPG\n",
    "fig.savefig(\"predictions.jpg\", format='jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
